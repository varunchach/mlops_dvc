{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7cb0774",
   "metadata": {},
   "source": [
    "# MLflow Inline Demo — Executable Notebook (No external .py files)\n",
    "\n",
    "This notebook demonstrates **MLflow with autologging** entirely *inline*: every step — data creation, model training, MLflow logging — runs inside notebook cells. No external `.py` files are created. Ideal for live teaching where learners run cells one-by-one.\n",
    "\n",
    "**How to use:**\n",
    "- Activate your virtualenv with `mlflow` installed before opening the notebook.\n",
    "- Start MLflow UI in a separate terminal to visualize runs: `mlflow ui --backend-store-uri sqlite:///mlflow.db --default-artifact-root ./mlruns`\n",
    "- Then run cells sequentially.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80e3e38",
   "metadata": {},
   "source": [
    "## 1) Environment check\n",
    "Run this cell to confirm mlflow and sklearn are available in your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355cacb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import mlflow\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "print('python', sys.version.split('\\n')[0])\n",
    "print('mlflow', mlflow.__version__)\n",
    "print('sklearn', sklearn.__version__)\n",
    "print('pandas', pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ba3b69",
   "metadata": {},
   "source": [
    "## 2) Create dataset (Iris) inline\n",
    "This creates `data/raw/iris.csv` and also keeps the dataframe in a variable for notebook use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb7ab4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd, os\n",
    "os.makedirs('data/raw', exist_ok=True)\n",
    "data = load_iris()\n",
    "df = pd.DataFrame(data=data['data'], columns=['sepal_length','sepal_width','petal_length','petal_width'])\n",
    "df['target'] = data['target']\n",
    "df.to_csv('data/raw/iris.csv', index=False)\n",
    "print('Wrote data/raw/iris.csv ->', len(df), 'rows')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a90518",
   "metadata": {},
   "source": [
    "## 3) Define parameters (as a python dict) — toggle `autolog` here\n",
    "You can edit values in this cell and re-run training cell below to create new experiments/runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20e19e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'data': {'raw_path': 'data/raw/iris.csv'},\n",
    "    'train': {\n",
    "        'test_size': 0.2,\n",
    "        'random_state': 42,\n",
    "        'max_iter': 200,\n",
    "        'C': 1.0,\n",
    "        'solver': 'lbfgs',\n",
    "        'experiment_name': 'mlops_demo_experiment',\n",
    "        'autolog': True\n",
    "    }\n",
    "}\n",
    "\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f883462",
   "metadata": {},
   "source": [
    "## 4) Training cell (inline) — uses MLflow autolog when `params['train']['autolog']` is True\n",
    "This cell trains a LogisticRegression, logs via MLflow (autolog + manual metrics), and prints the run id. Run it multiple times after changing `params` to create multiple runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a45227",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import joblib\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "# Use current params dict\n",
    "cfg = params\n",
    "train_cfg = cfg['train']\n",
    "\n",
    "# Optional: set tracking URI if you are using mlflow server\n",
    "# mlflow.set_tracking_uri('http://127.0.0.1:5000')\n",
    "\n",
    "# Enable autolog if requested\n",
    "if train_cfg.get('autolog', False):\n",
    "    mlflow.sklearn.autolog()\n",
    "    print('Autolog ENABLED')\n",
    "else:\n",
    "    print('Autolog DISABLED')\n",
    "\n",
    "# Read data\n",
    "import pandas as pd\n",
    "df = pd.read_csv(cfg['data']['raw_path'])\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=train_cfg['test_size'], random_state=train_cfg['random_state']\n",
    ")\n",
    "\n",
    "# Create experiment\n",
    "mlflow.set_experiment(train_cfg.get('experiment_name', 'default'))\n",
    "\n",
    "run_name = f\"notebook_run_{datetime.now(timezone.utc).strftime('%Y%m%dT%H%M%SZ')}\"\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    run_id = run.info.run_id\n",
    "    # manual param logging only if autolog is off\n",
    "    if not train_cfg.get('autolog', False):\n",
    "        mlflow.log_params({k: v for k, v in train_cfg.items() if k != 'experiment_name'})\n",
    "\n",
    "    model = LogisticRegression(max_iter=train_cfg['max_iter'], C=train_cfg['C'], solver=train_cfg.get('solver','lbfgs'))\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    preds = model.predict(X_test)\n",
    "    acc = float(accuracy_score(y_test, preds))\n",
    "    f1 = float(f1_score(y_test, preds, average='macro'))\n",
    "\n",
    "    mlflow.log_metric('accuracy_custom_eval', acc)\n",
    "    mlflow.log_metric('f1_macro_custom_eval', f1)\n",
    "\n",
    "    # save model artifact locally\n",
    "    import os\n",
    "    os.makedirs('models', exist_ok=True)\n",
    "    model_path = f\"models/logreg_{run_id}.joblib\"\n",
    "    joblib.dump(model, model_path)\n",
    "    mlflow.log_artifact(model_path, artifact_path='model')\n",
    "\n",
    "    # ensure skmodel logged (autolog may have done it)\n",
    "    mlflow.sklearn.log_model(model, artifact_path='skmodel')\n",
    "\n",
    "    print(f'Run {run_id} finished — accuracy={acc:.4f}, f1={f1:.4f}')\n",
    "\n",
    "run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21887bf",
   "metadata": {},
   "source": [
    "## 5) Inspect recent runs programmatically\n",
    "This cell lists recent runs and their metrics for the experiment defined in `params`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f85f75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow, pandas as pd\n",
    "exp = mlflow.get_experiment_by_name(params['train']['experiment_name'])\n",
    "if exp is None:\n",
    "    print('Experiment not found yet')\n",
    "else:\n",
    "    df_runs = mlflow.search_runs([exp.experiment_id], order_by=['start_time DESC'], max_results=20)\n",
    "    if df_runs.empty:\n",
    "        print('No runs found')\n",
    "    else:\n",
    "        display(df_runs[['run_id','status','metrics.accuracy_custom_eval','metrics.f1_macro_custom_eval','params.C','start_time']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b052f7",
   "metadata": {},
   "source": [
    "## 6) Load the latest logged model and run a prediction\n",
    "This cell auto-detects the latest finished run and loads its `skmodel` artifact via MLflow, then predicts a sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcb5392",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow.sklearn\n",
    "exp = mlflow.get_experiment_by_name(params['train']['experiment_name'])\n",
    "if exp is None:\n",
    "    print('Experiment not found')\n",
    "else:\n",
    "    df_runs = mlflow.search_runs([exp.experiment_id], order_by=['start_time DESC'], max_results=10)\n",
    "    if df_runs.empty:\n",
    "        print('No runs available')\n",
    "    else:\n",
    "        # find first finished run\n",
    "        done = df_runs[df_runs['status']=='FINISHED']\n",
    "        if done.empty:\n",
    "            print('No finished runs yet; wait or end active run')\n",
    "        else:\n",
    "            latest_run_id = done.iloc[0]['run_id']\n",
    "            model_uri = f\"runs:/{latest_run_id}/skmodel\"\n",
    "            print('Loading model from', model_uri)\n",
    "            model = mlflow.sklearn.load_model(model_uri)\n",
    "            print('Prediction for sample:', model.predict([[5.1,3.5,1.4,0.2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8be450a",
   "metadata": {},
   "source": [
    "## 7) Tips\n",
    "- To view the UI while running the notebook, start the MLflow UI in another terminal: `mlflow ui --backend-store-uri sqlite:///mlflow.db --default-artifact-root ./mlruns` and open http://127.0.0.1:5000\n",
    "- Toggle `params['train']['autolog']` to see autolog ON vs OFF, then re-run the training cell to create new runs.\n",
    "- If a run appears RUNNING, call `mlflow.end_run()` in a cell to finish it."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
